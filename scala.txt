Big Data Project

Student ID: xia02783
Student Name: Bo Xia

1. Data Source, description and schema:
All the data is about high-through output sequencing results' meta data, which including the metadata information about
sample id, experiment series id, sequencing method/strategy, organism of the sample source, characteristics of the sample.

Here is an example:
^SAMPLE = GSM64538
!Sample_title = H3K4Me3 Replicate 5 vs input | array 6_29
!Sample_geo_accession = GSM64538
!Sample_status = Public on Sep 01 2005
!Sample_submission_date = Jul 15 2005
!Sample_last_update_date = Jul 18 2005
!Sample_type = genomic
!Sample_channel_count = 2
!Sample_source_name_ch1 = aRNA-amplifed MNase digested DNA
!Sample_organism_ch1 = Saccharomyces cerevisiae
!Sample_taxid_ch1 = 4932
!Sample_characteristics_ch1 = Strain:  BY4741 bar1-
!Sample_molecule_ch1 = genomic DNA
!Sample_label_ch1 = Cy3-aadUTP
....



2. Preprocessing:

All 2 million meta data files of samples were downloaded from NCBI(ncbi.nlm.nih.gov) GEO database by following python scripts
All about 80k meta data files of Series experiments were downloaded from NCBI GEO database by following python scripts
ALL GSE, GSM id from acquired by parse through NCBI ftp sites.

The number of samples and series ID is based on the database before Nov 11th.


GSE Download python file:

from ftplib import FTP
import urllib
import os
import tarfile
import argparse


def grabFiles(directories, urlprefix='/geo/series/',
              file_surfix='.txt', partitionNumber=0):
    failDownloads = []
    for directory in directories:
        downloadAddress = "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc="+directory+"&targ=self&form=text&view=quick"
        print "downloading " + directory + " from " + downloadAddress
        # try:
        urllib.urlretrieve(downloadAddress, "/Users/boxia/Desktop/PycharmProjects/GEODataParser/GSESoftQuick/"+directory+file_surfix)
        # except:
        #
        #     error = 1
        #     while error <= 5:
        #         try:
        #             urllib.urlretrieve(downloadAddress, './Users/boxia/Desktop/PycharmProjects/GEODataParser/GSESoftQuick/'+directory+file_surfix)
        #             break
        #         except:
        #             error += 1
        #     if error >= 5:
        #         failDownloads.append(downloadAddress)
        #         print error
        #     continue
    print failDownloads
    with open('failDownLoadGSE'+str(partitionNumber), 'w') as file:
        for item in failDownloads:
            file.write("%s\n" % item)

def getPartition(length, number):
    numberSamplesPartition = length / number
    numberSamplesRemainder = length % number
    partitions = [
        [start * numberSamplesPartition, (start + 1) * numberSamplesPartition] if start != number - 1 else [
            start * numberSamplesPartition, (start + 1) * numberSamplesPartition + numberSamplesRemainder] for start in
        range(number)]
    return partitions

def MinimlDowloader(numberPartition, numberofPartitions=1):
    numberPartition = int(numberPartition)
    numberofPartitions = int(numberofPartitions)
    GSMs = []
    with open("/Users/boxia/Desktop/PycharmProjects/GEODataParser/failedGSESoftDownloads.txt", "r") as file:
        for line in file.readlines():
            GSMs.append(line.rstrip())
    start, end = getPartition(len(GSMs), numberofPartitions)[numberPartition]

    downloadFiles = GSMs[start: end]
    grabFiles(downloadFiles, partitionNumber=numberPartition)

# if __name__ == '__main__':
#     parser = argparse.ArgumentParser()
#     parser.add_argument('number', help='a file contains GSE', type=int)
#
#     args = parser.parse_args()
#
#     MinimlDowloader(args.number)


MinimlDowloader(0)


GSM Download python code:
from ftplib import FTP
import urllib
import os
import tarfile
import argparse


def grabFiles(directories, urlprefix='/geo/series/',
              file_surfix='.txt', partitionNumber=0):
    failDownloads = []
    for directory in directories:
        downloadAddress = "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc="+directory+"&targ=self&form=txt&view=quick"
        # print "downloading " + directory + " from " + downloadAddress
        try:
            urllib.urlretrieve(downloadAddress, './QuickXMLs/'+directory+file_surfix)
        except:

            error = 1
            while error <= 5:
                try:
                    urllib.urlretrieve(downloadAddress, './QuickXMLs/'+directory+file_surfix)
                    break
                except:
                    error += 1
            failDownloads.append(downloadAddress)
            continue
    with open('failDownloadsGSMXMLs'+str(partitionNumber), 'w') as file:
        for item in failDownloads:
            file.write("%s\n" % item)

def getPartition(length, number):
    numberSamplesPartition = length / number
    numberSamplesRemainder = length % number
    partitions = [
        [start * numberSamplesPartition, (start + 1) * numberSamplesPartition] if start != number - 1 else [
            start * numberSamplesPartition, (start + 1) * numberSamplesPartition + numberSamplesRemainder] for start in
        range(number)]
    return partitions

def MinimlDowloader(numberPartition, numberofPartitions=100):
    numberPartition = int(numberPartition)
    numberofPartitions = int(numberofPartitions)
    GSMs = []
    with open("./ALLGSMsID.txt", "r") as file:
        for line in file.readlines():
            GSMs.append(line.rstrip())
    start, end = getPartition(len(GSMs), numberofPartitions)[numberPartition]

    downloadFiles = GSMs[start: end]
    grabFiles(downloadFiles, partitionNumber=numberPartition)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('number', help='a file contains GSE', type=int)

    args = parser.parse_args()

    MinimlDowloader(args.number)


# MinimlDowloader(0)




Files were concatenated by linux command.
cat *.txt > BX.txt


3. bad data issues:

Data validation was cross validated by python parser.
No bad data problem in the field of sample id, series id, organism and sequencing strategy.


4. Scala Scripts:
Data was processed by following scala scripts:

scala> val mydata = sc.textFile("BX.txt")

scala> val filterMap = mydata.filter(x => x.startsWith("^SAMPLE"))
scala> val splitSpace = filterMap.map(x => x.replaceAll(" ", "").split("="))
scala> val allSampleName = splitSpace.map(x => (x(1)))
scala> val sampleMap = allSampleName.map(x => (x, x.substring(3).toInt))
scala> val sortedSamples = sampleMap.sortBy(pair => pair._2)
scala> val sortedSamplesID = sortedSamples.map(x => x._1)
scala> val GEOsampleIDs = sortedSamplesID.collect()
scala> GEOsampleIDs.length
res25: Int = 1996030

scala> val sampleOut = sc.parallelize(GEOsampleIDs)
scala> sampleOut.saveAsTextFile("GEOSampleID")



scala> val gseMap = mydata.filter(x => x.startsWith("!Sample_series_id"))
scala> val splitGSE = gseMap.map(x => x.replaceAll(" ", "").split("="))
scala> val allGSEs = splitGSE.map(x => (x(1)))
scala> val seriesMap = allGSEs.map(x => (x, x.substring(3).toInt))
scala> val sortedGSEs = seriesMap.sortBy(pair => pair._2).map(x => x._1).collect()

scala> val uniqueGSEs = sortedGSEs.distinct
scala> uniqueGSEs.length
res29: Int = 75856

scala> val gseOut = sc.parallelize(uniqueGSEs)
scala> gseOut.saveAsTextFile("GEOSeriesID")



scala> val creatureMap = mydata.filter(x => x.startsWith("!Sample_organism"))
scala> val splitcreature = creatureMap.map(x => x.split("="))
scala> val allCreature = splitcreature.map(x => (x(1).trim,1))
scala> val reduceCreature = allCreature.reduceByKey(_+_)
scala> val sortedCreature = reduceCreature.sortBy(_._2, false).collect()
scala> val creatureOut = sc.parallelize(sortedCreature)
scala> creatureOut.saveAsTextFile("GEOorganism")




scala> val seqMap = mydata.filter(x => x.startsWith("!Sample_library_strategy"))
scala> val splitSeq = seqMap.map(x => x.split("="))
scala> val allSeq = splitSeq.map(x => (x(1).trim,1))
scala> val reduceSeq = allSeq.reduceByKey(_+_)
scala> val sortedSeq = reduceSeq.sortBy(_._2, false).collect()
scala> val seqOut = sc.parallelize(sortedSeq)
scala> seqOut.saveAsTextFile("GEOseqeuncingStrategy")


[xia02783@hc ~]$ hadoop fs -ls
Found 26 items
drwx------   - xia02783 supergroup          0 2016-10-09 19:00 .Trash
drwxr-xr-x   - xia02783 supergroup          0 2016-12-03 14:29 .sparkStaging
drwx------   - xia02783 supergroup          0 2016-10-07 22:19 .staging
drwxr-xr-x   - xia02783 supergroup          0 2016-09-29 20:19 929w20
drwxr-xr-x   - xia02783 supergroup          0 2016-09-29 20:24 929wo20
drwxr-xr-x   - xia02783 supergroup          0 2016-10-07 21:16 As52Step1
drwxr-xr-x   - xia02783 supergroup          0 2016-10-07 21:52 As52Step2
drwxr-xr-x   - xia02783 supergroup          0 2016-10-07 22:18 As53Step1
drwxr-xr-x   - xia02783 supergroup          0 2016-10-07 22:18 As53Step2
drwxr-xr-x   - xia02783 supergroup          0 2016-10-07 21:08 As5Step1
-rw-r--r--   3 xia02783 supergroup 8343488613 2016-12-03 12:47 BX.txt
drwxr-xr-x   - xia02783 supergroup          0 2016-12-03 13:42 GEOSampleID
drwxr-xr-x   - xia02783 supergroup          0 2016-12-03 13:55 GEOSeriesID
drwxr-xr-x   - xia02783 supergroup          0 2016-12-03 14:20 GEOorganism
drwxr-xr-x   - xia02783 supergroup          0 2016-12-03 14:28 GEOseqeuncingStrategy
drwxr-xr-x   - xia02783 supergroup          0 2016-11-13 23:25 securityProtocolCount
drwxr-xr-x   - xia02783 supergroup          0 2016-09-30 22:04 stock
drwxr-xr-x   - xia02783 supergroup          0 2016-09-30 22:35 stock2
drwxr-xr-x   - xia02783 supergroup          0 2016-09-30 22:07 stockwp
drwxr-xr-x   - xia02783 supergroup          0 2016-09-30 22:27 stockwp2
drwxr-xr-x   - xia02783 supergroup          0 2016-09-30 22:31 stockwp3
drwxr-xr-x   - xia02783 supergroup          0 2016-10-28 19:58 top100RDD
drwxr-xr-x   - xia02783 supergroup          0 2016-09-23 21:22 xia0278320
drwxr-xr-x   - xia02783 supergroup          0 2016-09-23 20:49 xia02783w
drwxr-xr-x   - xia02783 supergroup          0 2016-09-23 21:23 xia02783w20
drwxr-xr-x   - xia02783 supergroup          0 2016-09-23 21:15 xia02783wo20



5. output description
These are the examples of results:

Example of GEO Sample ID:
GSM1
GSM2
GSM3
GSM4
GSM5
GSM6
GSM7
GSM8
GSM9
GSM10
GSM11
GSM12
GSM13
GSM14
GSM15
GSM16
GSM17
GSM18
GSM19
GSM20
GSM21
GSM22
GSM23
GSM24
GSM25
GSM26
GSM27
GSM28
GSM29
GSM30
GSM31
GSM32
GSM33
GSM34
GSM35
GSM36
GSM37
GSM38
GSM39
GSM40





Example of GEO Series ID:
GSE1
GSE2
GSE3
GSE4
GSE5
GSE6
GSE7
GSE8
GSE9
GSE10
GSE11
GSE12
GSE13
GSE14
GSE15
GSE16
GSE17
GSE18
GSE19
GSE20
GSE21
GSE22
GSE23
GSE24
GSE25
GSE26
GSE27
GSE28
GSE29
GSE30
GSE31
GSE32
GSE33
GSE34
GSE35
GSE36
GSE37
GSE38
GSE39
GSE40





Example of Organisms:
(Homo sapiens,1321357)
(Mus musculus,398715)
(Rattus norvegicus,83783)
(Saccharomyces cerevisiae,68541)
(Arabidopsis thaliana,46974)
(Drosophila melanogaster,38421)
(Sus scrofa,15331)
(Bos taurus,13747)
(Caenorhabditis elegans,13299)
(Danio rerio,12921)
(Zea mays,12799)
(Oryza sativa,10990)
(Gallus gallus,8975)
(Escherichia coli,7976)
(Plasmodium falciparum,7432)
(Glycine max,7297)
(Macaca mulatta,7193)
(Canis lupus familiaris,6703)
(synthetic construct,6467)
(Schizosaccharomyces pombe,5669)
(Pimephales promelas,4146)
(Halobacterium salinarum NRC-1,3972)
(Macaca fascicularis,3747)
(Oncorhynchus mykiss,3505)
(Salmonella enterica subsp. enterica serovar Typhimurium,3437)
(Triticum aestivum,3409)
(Candida albicans,3321)
(Staphylococcus aureus,3033)
(Mycobacterium tuberculosis,2996)
(Mycobacterium tuberculosis H37Rv,2805)
(Bacillus subtilis,2725)
(Vitis vinifera,2573)
(Salmo salar,2524)
(Oryza sativa Japonica Group,2499)
(Escherichia coli str. K-12 substr. MG1655,2474)
(Solanum tuberosum,2462)
(Helicobacter pylori,2420)
(Ovis aries,2396)
(Hordeum vulgare,2299)
(Solanum lycopersicum,1903)
(Campylobacter jejuni,1768)
(Daphnia magna,1640)



Sequencing Strategy
(RNA-Seq,218570)
(ChIP-Seq,50288)
(OTHER,25495)
(Bisulfite-Seq,10845)
(miRNA-Seq,6854)
(ncRNA-Seq,3878)
(RIP-Seq,1727)
(DNase-Hypersensitivity,1588)
(MNase-Seq,1538)
(MeDIP-Seq,1508)
(MBD-Seq,879)
(MRE-Seq,301)
(FAIRE-seq,256)
(WGS,47)
(ChIA-PET,43)
(SELEX,35)
(AMPLICON,7)
(Tn-Seq,2)
(FL-cDNA,2)



6. Verification of output:
cross validation is performed by following python parser:

from xml.dom import minidom
from GSM import GSM
import os
import re
import json
from collections import defaultdict
import csv

def SOFTQuickParser(cwd=None):
    if cwd == None:
        return

    # print len(map)
    # samples = {}

    Human_Samples = {}

    # totalOrganismsName = defaultdict(int)
    # totalCharacteristicsName = defaultdict(int)
    # featureMeasage = defaultdict(list)

    # notFeature = {}

    # AllUniqueGSEs = set()
    #
    # HumanWithH3K4me3Download = set()

    # n = 0
    # relatedSamples = {}


    # relatedGSMs = set()
    # file =  open("allUniqueGSMsHumanWithH3K4me3.txt", "r")
    # for line in file.readlines():
    #     relatedGSMs.add(line.strip())
    # file.close()

    for filename in os.listdir(cwd)[0:10000]:
        if not filename.startswith("GSM"):
            continue


        file = open(cwd+'/'+filename, "r")
        characteristics = defaultdict(str)
        supplementaryData = defaultdict(str)
        relations = defaultdict(str)
        sampleSeriesID = set()
        feature = {}

        antibody = {}
        treatment = {}
        tissue = None
        disease = None
        cellLine = ""
        cellType = ""
        genoType = {}
        title_found = False
        ab_found = False

        for line in file.readlines():
            if line.startswith("^SAMPLE"):
                sampleName = line[line.find("=")+1:].strip()
            if line.startswith("!Sample_title"):
                sampleTitle = line[line.find("=")+1:].strip()
                if re.search("h3k4me3", sampleTitle, flags=re.IGNORECASE):
                    feature["Title"] = sampleTitle
                    title_found = True
            if line.startswith("!Sample_type"):
                sampleType = line[line.find("=")+1:].strip()
            if line.startswith("!Sample_organism"):
                sampleOrganism = line[line.find("=")+1:].strip()
            if line.startswith("!Sample_characteristics_ch"):
                characteristic = line[line.find("=")+1:].strip()
                key, value = characteristic[:characteristic.find(":")].strip(), characteristic[characteristic.find(":")+1:].strip()
                if key in characteristics:
                    characteristics[key] += ", " + value
                else:
                    characteristics[key] = value
                if re.search("h3k4me3", value, flags=re.IGNORECASE):
                    feature[key] = value
            if line.startswith("!Sample_platform_id "):
                samplePlatForm = line[line.find("=")+1:].strip()
            if line.startswith("!Sample_library_strategy"):
                sampleLibraryStrategy = line[line.find("=")+1:].strip()
            if line.startswith("!Sample_supplementary"):
                dataUrl = line[line.find("=")+1:].strip()
                keyName = "Data" + str(len(supplementaryData)+1)
                supplementaryData[keyName] = dataUrl
            if line.startswith("!Sample_relation"):
                relation = line[line.find("=")+1:].strip()
                key, value = relation[:relation.find(":")].strip(), relation[relation.find(":") + 1:].strip()
                relations[key] = value
            if line.startswith("!Sample_series_id"):
                sampleSeriesID.add(line[line.find("=")+1:].strip())
            if line.startswith("!Sample_instrument_model"):
                sampleInstrumentID = line[line.find("=")+1:].strip()

        sample = GSM(sampleName)
        sample.characteristics = characteristics
        sample.supplementaryData = supplementaryData
        sample.title = sampleTitle
        sample.type = sampleType
        sample.libraryStrategy = sampleLibraryStrategy
        sample.organism = sampleOrganism
        sample.SRA = relations["SRA"]
        sample.series = list(sampleSeriesID)

        sample.platForm = samplePlatForm
        sample.features = feature
        sample.InstrumentID = sampleInstrumentID

        for key, value in characteristics.items():
            if key.lower() in ["chip antibody", "chip", "antigen", "antibody", "antibodies", "chip antibodies",
                               "antibody name", "antibody target", "target", "antibody/capture", "antibody/vendor/catalog#",
                               "chip ab", "chip antibody1", "chip antibody2", "chip-antibody", "chip_antibody",
                               "chip-seq antibody", "chip_antibodies", "chip-antibodies", "histone mark", "epigenetic feature",
                               "histone modification", "antibody antibodydescription", "chip antibody (epitope/name)",
                               "factor", "chip antibody/mbd affinity column", "chip/dip antibody", "antibody epiptope",
                               "antibody source", 'modification', "antibody (vendor': ' catalog#, or reference)",
                               "experiment", "purification antibody", "antibody/details", "antibody epiptope",
                               "antibody information", "chip antibody / digestive enzyme", "chip antiboy",
                               "ip antibody", "chip antibody target", "modification", "histone", "enrichment procedure",
                               "antibody (vendor': ' catalog#, or reference)", "developmental stage/condition/extract protocol",
                               "antibody source"] \
                    or re.search('antibody epitope|using[\w\s]+antibod|immunoprecipitat', key, flags=re.IGNORECASE):
                if key in antibody:
                    antibody[key] += ", " + value
                else:
                    antibody[key] = value
            if key.lower() in ["treatment", "condition", "activation stimuli", "cell condition", "cell treatment",
                               "cell-treatment", "drug treatment", "stress", "overexpression", "treatment drug",
                               "treatment group"] \
                    or re.search("(?:dsrna|infect|rnai|shrna|sirna|transduc|transfec|agent[#]*[0-9]*|activat)", key, flags=re.IGNORECASE):
                treatment[key] = value

            if key.lower() in ["tissue", "body part", "body site"]:
                tissue = value

            if key.lower() in ["cancer type", "tumor type", "tumor region", "disease", "disease state", "disease status"]:
                disease = value

            if key.lower() in ["background strain", "strain", "strain number", "mouse strain", "strain background",
                               "cell line background", "genetic background", "genotype", "genotype/variation",
                               "strain/background", "variation"]:
                genoType[key] = value

            if key.lower() in ["cell line",  "cell", "cells pointed by barcodes",
                           "chicken line", "line"]:
                cellLine += value

            if key.lower() in ["cell_type", "cell-type", "cell type", "cell lineage"]:
                cellType += value

        sample.antibody = antibody
        for value in sample.antibody.values():
            if re.search("h3k4me3", value, flags=re.IGNORECASE):
                ab_found = True
                break




        sample.treatment = treatment
        sample.disease = disease
        sample.cellLine = cellLine
        sample.genotype = genoType
        sample.tissue = tissue
        sample.title_found = title_found
        sample.ab_found = ab_found
        if title_found or ab_found:
            sample.title_ab = True

        if sample.organism == "Homo sapiens" and (sample.SRA != None and sample.SRA.strip() != "") and \
                sample.InstrumentID.startswith('Illu') and sample.libraryStrategy.lower() == "chip-seq":
            if sample.title_ab == True:
                # AllUniqueGSEs = AllUniqueGSEs.union(sample.series)
                Human_Samples[sample.id] = sample
                # HumanWithH3K4me3Download.add(sample.SRA)
            # elif sample.id in relatedGSMs:
            #     relatedSamples[sample.id] = sample

        file.close()

        # for char in characteristics.keys():
        #     totalCharacteristicsName[char]+=1
        # if len(feature) != 0:
        #     samples[sampleName] = sample
        #     totalOrganismsName[sampleOrganism]+=1
        # else:
        #     notFeature[sampleName] = sample

    # with open("./GEOSearchXMLs/geoSoftParserResult", "w") as file:
    #     for value in samples.values():
    #         json.dump(value.__dict__, file)
    # with open("./GEOSearchXMLs/geoSoftParserNoFeatureResult", "w") as file:
    #     for value in notFeature.values():
    #         json.dump(value.__dict__, file)
    # #
    # with open("./GEOSearchXMLs/geoorganimsWithH3K4me3.csv", "wb") as csv_file:
    #     writer = csv.writer(csv_file)
    #     for key, value in totalOrganismsName.items():
    #         writer.writerow([key, value])
    # #
    # with open("./GEOSearchXMLs/geocharacteristics.csv", "wb") as csv_file:
    #     writer = csv.writer(csv_file)
    #     for key, value in totalCharacteristicsName.items():
    #         writer.writerow([key, value])
    #
    # with open("./GEOSearchXMLs/geocontainingMessageWithH3K4me3.csv", "wb") as csv_file:
    #     writer = csv.writer(csv_file)
    #     for key, value in featureMeasage.items():
    #         writer.writerow([key, value])
    #         writer.writerow(["     "])

    # with open("./GEOSearchXMLs/geoH3K4me3GSMList.csv", "wb") as csv_file:
    #     writer = csv.writer(csv_file)
    #     writer.writerow(
    #         ['Sample_ID', "Title", "Organism", "Series_ID", "GPL_ID", "Instrument Model", "SRA_ID", "Library Strategy",
    #          "H3K4me3_description", "Tissue", "Cell Line", "Cell Type", "Disease", "Treatment", "Genotype", "Antibody", "Feature in Title", "Feature in Ab",
    #          "Feature in Title or Ab"])
    #     for sample in samples.values():
    #         writer.writerow(
    #             [sample.id, sample.title, sample.organism, sample.series, sample.platForm, sample.InstrumentID,
    #              sample.SRA, sample.libraryStrategy, sample.features, sample.tissue, sample.cellLine, sample.cellType,
    #              sample.disease, sample.treatment, sample.genotype, sample.antibody, sample.title_found, sample.ab_found,
    #              sample.title_ab])

    csv_file = open("./HumanH3K4me3GSMList.csv", "wb")
    writer = csv.writer(csv_file)
    writer.writerow(
        ['Sample_ID', "Title", "Organism", "Series_ID", "GPL_ID", "Instrument Model", "SRA_ID", "Library Strategy",
         "H3K4me3_description", "Tissue", "Cell Line", "Cell Type", "Disease", "Treatment", "Genotype", "Antibody", "Feature in Title",
         "Feature in Ab", "Feature in Title or Ab"])
    for sample in Human_Samples.values():
        writer.writerow(
            [sample.id, sample.title, sample.organism, sample.series, sample.platForm, sample.InstrumentID,
             sample.SRA, sample.libraryStrategy, sample.features, sample.tissue, sample.cellLine, sample.cellType,
             sample.disease, sample.treatment, sample.genotype, sample.antibody, sample.title_found, sample.ab_found,
             sample.title_ab])
    csv_file.close()


    # csv_file =  open("./HumanH3K4me3RelatedSamples.csv", "wb")
    # writer = csv.writer(csv_file)
    # writer.writerow(
    #     ['Sample_ID', "Title", "Organism", "Series_ID", "GPL_ID", "Instrument Model", "SRA_ID",
    #      "Library Strategy",
    #      "H3K4me3_description", "Tissue", "Cell Line", "Cell Type", "Disease", "Treatment", "Genotype",
    #      "Antibody", "Feature in Title",
    #      "Feature in Ab", "Feature in Title or Ab"])
    # for sample in relatedSamples.values():
    #     writer.writerow(
    #         [sample.id, sample.title, sample.organism, sample.series, sample.platForm, sample.InstrumentID,
    #          sample.SRA, sample.libraryStrategy, sample.features, sample.tissue, sample.cellLine,
    #          sample.cellType,
    #          sample.disease, sample.treatment, sample.genotype, sample.antibody, sample.title_found,
    #          sample.ab_found,
    #          sample.title_ab])
    # csv_file.close()

    # with open("./GEOSearchXMLs/notFeature.csv", "w") as csv_file:
    #     writer = csv.writer(csv_file)
    #     writer.writerow(['Sample_ID', "Title", "Organism", "Series_ID", "GPL_ID", "Instrument Model", "SRA_ID", "Library Strategy",
    #          "H3K4me3_description", "Tissue", "Cell Line", "Disease", "Treatment", "Genotype", "Antibody", "Feature in Title", "Feature in Ab"])
    #     for sample in notFeature.values():
    #         writer.writerow(
    #             [sample.id, sample.title, sample.organism, sample.series, sample.platForm, sample.InstrumentID,
    #              sample.SRA, sample.libraryStrategy, sample.features, sample.tissue, sample.cellLine,
    #              sample.disease, sample.treatment, sample.genotype, sample.antibody, sample.title_found, sample.ab_found])

    # with open("./allUniqueGSEsHumanWithH3K4me3.txt", "w") as file:
    #     for value in AllUniqueGSEs:
    #         file.write(value+"\n")
    #
    # with open("./HumanWithH3K4me3Download.txt", "w") as file:
    #     for value in HumanWithH3K4me3Download:
    #         file.write(value+"\n")
    return

# for key, value in MinimlXMLParser().iteritems():
#     print value.title
# SOFTQuickParser("./GEOSearchXMLs")
# values.sort(key=lambda x:x.title)




# print "There are total ", len(samples), " samples"

# print "There are total", len(noFeature), " samples don't have features"
# print organismsName
# print "Has ", len(organismsName), " different Characteristics"
# print characteristicsName

SOFTQuickParser("./QuickXMLs")



7. performance/scale characteristics
Scala is outperformed traditional python parser in terms of reduce and count.
The performance to deal with complicated data description (such as the field of antibody, treatment, cell type, which don't have
consistent data format) is not compared.

I can't provide specific comparison because I run python parser on our own HPC and scala was run on the St thomas HPC.



8. what would you have done differently if you did this again?
I am not sure about the scala's application if I don't concatenate the files together. Clearly, separate files would be
 helpful to group different types of samples.


9. conclusions
Due to the dramatic cost reduction on next-generation of sequencing technology, sequencing data is growing dramatically.
To date, there are 75865 experiment studies and 1996030 samples on the NCBI GEO database. Significantly, sequencing on
human samples is 1321357 and most common sequencing strategy is RNA-seq 218570 (study on gene expression) and ChIP-Seq 50288
(study the epigenetics). Future work will be included such as group different types of ChIP-seq data and build efficient database,
finding the corresponding control or input samples for each samples, automatically fetech the ftp url for user to easily download
the data.
